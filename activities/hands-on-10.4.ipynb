{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 10.4: The point-predictive Distribution - Separating Epistmic and Aleatory Uncertainty\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ To demonstrate how epistemic from aleatory uncertainty can be separated.\n",
    "\n",
    "## Example (Quadratic)\n",
    "\n",
    "Let's repeat what we did above with a quadratic example.\n",
    "Here are some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations we have\n",
    "num_obs = 10\n",
    "x = -1.0 + 2 * np.random.rand(num_obs)\n",
    "w0_true = -0.5\n",
    "w1_true = 2.0\n",
    "w2_true = 2.0\n",
    "sigma_true = 0.1\n",
    "y = w0_true + w1_true * x + w2_true * x ** 2 + sigma_true * np.random.randn(num_obs)\n",
    "# Let's plot the data\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(x, y, 'x', label='Observed data')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also copy-paste the code from previous hands-on activities for generating the design matrix and fitting the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def get_polynomial_design_matrix(x, degree):\n",
    "    \"\"\"\n",
    "    Returns the polynomial design matrix of ``degree`` evaluated at ``x``.\n",
    "    \"\"\"\n",
    "    # Make sure this is a 2D numpy array with only one column\n",
    "    assert isinstance(x, np.ndarray), 'x is not a numpy array.'\n",
    "    assert x.ndim == 2, 'You must make x a 2D array.'\n",
    "    assert x.shape[1] == 1, 'x must be a column.'\n",
    "    # Start with an empty list where we are going to put the columns of the matrix\n",
    "    cols = []\n",
    "    # Loop over columns and add the polynomial\n",
    "    for i in range(degree+1):\n",
    "        cols.append(x ** i)\n",
    "    return np.hstack(cols)\n",
    "\n",
    "def get_fourier_design_matrix(x, L, num_terms):\n",
    "    \"\"\"\n",
    "    Fourier expansion with ``num_terms`` cosines and sines.\n",
    "    \"\"\"\n",
    "    # Make sure this is a 2D numpy array with only one column\n",
    "    assert isinstance(x, np.ndarray), 'x is not a numpy array.'\n",
    "    assert x.ndim == 2, 'You must make x a 2D array.'\n",
    "    assert x.shape[1] == 1, 'x must be a column.'\n",
    "    N = x.shape[0]\n",
    "    cols = [np.ones((N, 1))]\n",
    "    # Loop over columns and add the polynomial\n",
    "    for i in range(1, int(num_terms / 2)):\n",
    "        cols.append(np.cos(2 * i * np.pi / L * x))\n",
    "        cols.append(np.sin(2 * i * np.pi / L * x))\n",
    "    return np.hstack(cols)\n",
    "                    \n",
    "def get_rbf_design_matrix(x, x_centers, ell):\n",
    "    # Make sure this is a 2D numpy array with only one column\n",
    "    assert isinstance(x, np.ndarray), 'x is not a numpy array.'\n",
    "    assert x.ndim == 2, 'You must make x a 2D array.'\n",
    "    assert x.shape[1] == 1, 'x must be a column.'\n",
    "    N = x.shape[0]\n",
    "    cols = [np.ones((N, 1))]\n",
    "    # Loop over columns and add the polynomial\n",
    "    for i in range(x_centers.shape[0]):\n",
    "        cols.append(np.exp(-(x - x_centers[i]) ** 2 / ell))\n",
    "    return np.hstack(cols)\n",
    "\n",
    "def find_m_and_S(Phi, y, sigma2, alpha):\n",
    "    \"\"\"\n",
    "    Return the posterior mean and covariance of the weights of a Bayesian linear regression problem with\n",
    "    design matrix ``Phi`` observed targets ``y``, noise variance ``sigma2``\n",
    "    and priors for the weights ``alpha``.\n",
    "    \"\"\"\n",
    "    A = np.dot(Phi.T, Phi) / sigma2 + alpha * np.eye(Phi.shape[1])\n",
    "    L = scipy.linalg.cho_factor(A)\n",
    "    m = scipy.linalg.cho_solve(L, np.dot(Phi.T, y / sigma2))\n",
    "    S = scipy.linalg.cho_solve(L, np.eye(Phi.shape[1]))\n",
    "    return m, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we fit a $7$ degree polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "# Select polynomial degree and get design matrix\n",
    "degree = 7\n",
    "Phi = get_polynomial_design_matrix(x[:, None], degree)# Pick variance (here I am using the true one)\n",
    "sigma2 = 0.1 ** 2\n",
    "# Pick the regularization parameter:\n",
    "alpha = 5.0\n",
    "# The prior for the weights\n",
    "w_prior = st.multivariate_normal(mean=np.zeros(degree+1), cov=alpha * np.eye(degree+1))\n",
    "# Solve for the MAP of the weights:\n",
    "m, S = find_m_and_S(Phi, y, sigma2, alpha)\n",
    "# The posterior of the weights\n",
    "w_post = st.multivariate_normal(mean=m, cov=S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the video, it is possible to get the posterior point predictive distribution for $y$ conditioned on $\\mathbf{x}$ and to separate aleatory from epistemic uncertainty.\n",
    "The posterior point predictive is:\n",
    "$$\n",
    "s^2(\\mathbf{x}) = \\boldsymbol{\\phi}(\\mathbf{x})^T\\mathbf{S}\\boldsymbol{\\phi}(\\mathbf{x}) + \\sigma^2.\n",
    "$$\n",
    "+ $\\sigma^2$ corresponds to the measurement noise.\n",
    "+ $\\boldsymbol{\\phi}(\\mathbf{x})^T\\mathbf{S}\\boldsymbol{\\phi}(\\mathbf{x})$ is the epistemic uncertainty induced by limited data.\n",
    "\n",
    "Here is how to visualize both of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "# Some points on which to evaluate the regression function\n",
    "xx = np.linspace(-1, 1, 100)\n",
    "Phi_xx = get_polynomial_design_matrix(xx[:, None], degree)\n",
    "yy_mean = np.dot(Phi_xx, m)\n",
    "yy_var = np.einsum('ij,jk,ik->i', Phi_xx, S, Phi_xx)\n",
    "yy_measured_var = yy_var + sigma2\n",
    "yy_std = np.sqrt(yy_var)\n",
    "yy_measured_std = np.sqrt(yy_measured_var)\n",
    "# Epistemic lower bound\n",
    "yy_le = yy_mean - 2.0 * yy_std\n",
    "# Epistemic upper bound\n",
    "yy_ue = yy_mean + 2.0 * yy_std\n",
    "# Epistemic + aleatory lower bound\n",
    "yy_lae = yy_mean - 2.0 * yy_measured_std\n",
    "# Episemic + aleatory upper bound\n",
    "yy_uae = yy_mean + 2.0 * yy_measured_std\n",
    "ax.plot(xx, yy_mean, 'r')\n",
    "ax.fill_between(xx, yy_le, yy_ue, color='red', alpha=0.25)\n",
    "ax.fill_between(xx, yy_lae, yy_le, color='green', alpha=0.25)\n",
    "ax.fill_between(xx, yy_ue, yy_uae, color='green', alpha=0.25)\n",
    "# plot the data again\n",
    "ax.plot(x, y, 'kx', label='Observed data')\n",
    "# The true connection between x and y\n",
    "yy_true = w0_true + w1_true * xx + w2_true * xx ** 2\n",
    "# overlay the true \n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Rerun the code cells above with a very small $\\alpha$. What happens?\n",
    "+ Rerun he code cells above with a very big $\\alpha$. What happens?\n",
    "+ Fix $\\alpha$ to $5$ and rerun the code cells above with a very small and the very big value for $\\sigma$. What happens in each case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
