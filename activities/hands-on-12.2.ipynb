{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 12.2: Density estimation via Gaussian mixtures\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ To demonstrate density estimation via Gaussian mixtures\n",
    "\n",
    "Again, we are going to demonstrate the concepts using a synthetic example.\n",
    "Let's generate the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the random seed so that we all get the same data\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Make synthetic dataset for clustering\n",
    "num_clusters_true = 3\n",
    "# The means of each cluster\n",
    "mu_true = 5.0 * np.random.randn(num_clusters_true, 2)\n",
    "# The variance of the observations around the cluster\n",
    "# Covariance of each cluster\n",
    "Sigmas = []\n",
    "for i in range(num_clusters_true):\n",
    "    u = 0.5 * np.random.randn(2, 1)\n",
    "    v = 0.5 * np.random.randn(2, 1)\n",
    "    Sigma = np.dot(u, u.T) + np.dot(v, v.T)\n",
    "    Sigmas.append(Sigma)\n",
    "# How many observations to generate per cluster\n",
    "num_obs_cluster = [50, 50, 50]\n",
    "#num_obs_cluster = [50] * num_clusters_true\n",
    "# Generate the data\n",
    "data = []\n",
    "for i in range(num_clusters_true):\n",
    "    x_i = np.random.multivariate_normal(mu_true[i], Sigmas[i], \n",
    "                                        size=num_obs_cluster[i])\n",
    "    data.append(x_i)\n",
    "data = np.vstack(data)\n",
    "# Permute the data so that order info is lost\n",
    "data = np.random.permutation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(data[:, 0], data[:, 1], '.')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the [sciki-learn implementation](https://scikit-learn.org/stable/modules/mixture.html) of Gaussian mixtures.\n",
    "Here is how you can set up a model and fit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import that Gaussian mixtures class\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Initialize and fit\n",
    "model = GaussianMixture(n_components=3).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we picked 3 components for the mixture (which happens to be the true number of mixtures).\n",
    "Here are the three mean vectors identified by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.means_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these to the true mean vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model identifies one covariance matrix per mixture component.\n",
    "These are stored in a 3D array (first dimension = mixture component).\n",
    "Here is how to access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.covariances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the Gaussian mixture model is essentially fitting the joint probability density function of the data, say $p(\\mathbf{x})$.\n",
    "In 2D, you can plot the contours of this probability density function.\n",
    "As a matter of fact, we are going to plot the contours of the logarithm of the probability function, i.e., the contours of $\\log p(\\mathbf{x})$.\n",
    "Here is how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a bunch of x points\n",
    "x = np.linspace(-9., 8.)\n",
    "# Pick a bunch of y points\n",
    "y = np.linspace(-9., 8.)\n",
    "# Make a grid (X and Y are 50 x 50 matrices. \n",
    "# The coordinates of the i, j grid point Are X[i, j], Y[i, j]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "# Put the grid coordinates in a (50^2) x 2 array because this is what scikit likes\n",
    "XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "# Get the log probability on the grid points\n",
    "z = model.score_samples(XX)\n",
    "# Respahe z \n",
    "Z = z.reshape(X.shape)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "c = ax.contour(X, Y, Z, levels=np.linspace(-400, 1.0, 30))\n",
    "plt.colorbar(c)\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the Gaussian mixture model to cluster the data.\n",
    "Clustering is performed as following.\n",
    "For each point $\\mathbf{x}$ that you would like to cluster:\n",
    "- calculate the probability $p_k$ that the point belongs to the $k$-th mixture component, i.e., calculate:\n",
    "$$\n",
    "p_k = \\frac{\\pi_kN(\\mathbf{x}|\\boldsymbol{\\mu}_k,\\boldsymbol{\\Sigma}_k)}{\\sum_{k'=1}^K\\pi_{k'}N(\\mathbf{x}|\\boldsymbol{\\mu}_{k'},\\boldsymbol{\\Sigma}_{k'})}.\n",
    "$$\n",
    "- assign the point to the cluster $k^*$ with the highest probability, i.e.,\n",
    "$$\n",
    "k^* = \\arg\\max_{k}p_k.\n",
    "$$\n",
    "Scikit-learn already implements this functionality.\n",
    "Here is how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering with this model\n",
    "labels = model.predict(data)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very useful thing that you can do is sample from the estimated probability density.\n",
    "This can be implemented through the following procedure:\n",
    "+ sample a mixture component $k$ in $1,\\dots,K$, with probability $\\pi_k$, i.e., sample from the Categorical random variable $\\operatorname{Categorical}(\\pi_1,\\dots,\\pi_K)$.\n",
    "+ then sample an $\\mathbf{x}$ from the Gaussian $N(\\boldsymbol{\\mu}_k,\\boldsymbol{\\Sigma}_k)$.\n",
    "Again, scikit-learn implements this for you.\n",
    "Here is how to access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from the density\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "# We are going to sample 10,000 times\n",
    "s_data, labels = model.sample(10000)\n",
    "ax.scatter(s_data[:, 0], s_data[:, 1])\n",
    "ax.set_xlabel('$x_1$');\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Everything works as expected when we use just the right number of components.\n",
    "Let's see what happens when we use the wrong number of components.\n",
    "We are going to start with fewer components than the right number.\n",
    "Let's try 2 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying fewer components\n",
    "model = GaussianMixture(n_components=2).fit(data)\n",
    "x = np.linspace(-9., 8.)\n",
    "y = np.linspace(-9., 8.)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "Z = model.score_samples(XX)\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "c = ax.contour(X, Y, Z, levels=np.linspace(-400, 0.0, 30))\n",
    "plt.colorbar(c)\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the model is grouping two of the components together.\n",
    "It puts them in the same Gaussian.\n",
    "That's the best it can do with two components.\n",
    "This is clearly underfitting.\n",
    "\n",
    "Let's now try more components than the right number.\n",
    "We are going to do 5.\n",
    "Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying fewer components\n",
    "model = GaussianMixture(n_components=5).fit(data)\n",
    "x = np.linspace(-9., 8.)\n",
    "y = np.linspace(-9., 8.)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "Z = model.score_samples(XX)\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "c = ax.contour(X, Y, Z, levels=np.linspace(-400, 0.0, 30))\n",
    "plt.colorbar(c)\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density doesn't look very bad even though we used more components.\n",
    "(The density will start looking bad if you use more components).\n",
    "How does the clustering look like when we use five componets.\n",
    "Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering with this model\n",
    "labels = model.predict(data)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. The model found five clusters (because we asked for them), but we can visually see in this example that it is overfitting.\n",
    "\n",
    "Let's now apply the Bayesian information criterion (BIC) to select the number of cluster.\n",
    "First, we loop over all models with 1 to 10 components and we calculate the BIC for each one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with different number of components and estimate BIC\n",
    "bics = []\n",
    "models = []\n",
    "for nc in range(1, 10):\n",
    "    m = GaussianMixture(n_components=nc).fit(data)\n",
    "    bics.append(m.bic(data))\n",
    "    models.append(m)\n",
    "bics = np.array(bics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the BICS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.bar(range(1, 10), bics)\n",
    "ax.set_ylabel('BIC Score')\n",
    "ax.set_xlabel('Number of components');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the model with the smallest BIC is the best.\n",
    "For this synthetic dataset the procedure selects 3 components which happens to be the right number.\n",
    "\n",
    "## Questions\n",
    "\n",
    "+ Change the random seed a couple of times (to whatever integer you want) and generate a few more examples.\n",
    "\n",
    "+ Change the number of true components in the synthetic dataset to 5 and repeat. Does BIC work?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
