{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 10.1: Probabilistic interpretation of least squares - Estimating the measurement noise\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ To demonstrate the correspondence between maximum likelihood and least squares\n",
    "\n",
    "## Running example\n",
    "\n",
    "Let's reuse our synthetic dataset:\n",
    "$$\n",
    "y_i = -0.5 + 2 x_i + + 2 x_i^2 + 0.1\\epsilon_i,\n",
    "$$\n",
    "where $\\epsilon_i \\sim N(0,1)$ and where we sample $x_i \\sim U([0,1])$.\n",
    "Here is how to generate this synthetic dataset and how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations we have\n",
    "num_obs = 10\n",
    "x = -1.0 + 2 * np.random.rand(num_obs)\n",
    "w0_true = -0.5\n",
    "w1_true = 2.0\n",
    "w2_true = 2.0\n",
    "sigma_true = 0.1\n",
    "y = w0_true + w1_true * x + w2_true * x ** 2 + sigma_true * np.random.randn(num_obs)\n",
    "# Let's plot the data\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(x, y, 'x', label='Observed data')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be fitting polynomials, so let's copy-paste the code we developed for computing the design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_design_matrix(x, degree):\n",
    "    \"\"\"\n",
    "    Returns the polynomial design matrix of ``degree`` evaluated at ``x``.\n",
    "    \"\"\"\n",
    "    # Make sure this is a 2D numpy array with only one column\n",
    "    assert isinstance(x, np.ndarray), 'x is not a numpy array.'\n",
    "    assert x.ndim == 2, 'You must make x a 2D array.'\n",
    "    assert x.shape[1] == 1, 'x must be a column.'\n",
    "    # Start with an empty list where we are going to put the columns of the matrix\n",
    "    cols = []\n",
    "    # Loop over columns and add the polynomial\n",
    "    for i in range(degree+1):\n",
    "        cols.append(x ** i)\n",
    "    return np.hstack(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, we saw that when least squares are interpreted probabilistically the weight estimate does not change.\n",
    "So, we can obtain it just like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The degree of the polynomial\n",
    "degree = 2\n",
    "# The design matrix\n",
    "Phi = get_polynomial_design_matrix(x[:, None], degree)\n",
    "# Solve the least squares problem\n",
    "w, sum_res, _, _ = np.linalg.lstsq(Phi, y, rcond=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have now also stored the second output of ``numpy.linalg.lstsq``. This is the sum of the residuals, i.e., it is:\n",
    "$$\n",
    "\\sum_{i=1}^N\\left[y_i - \\sum_{j=1}^mw_j\\phi_j(x_i)\\right]^2 = \\parallel \\mathbf{y} - \\mathbf{\\Phi}\\mathbf{w}\\parallel_2^2.\n",
    "$$\n",
    "Let's test this just to be sure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sum_res = {0:1.4f}'.format(sum_res[0]))\n",
    "print('compare to = {0:1.4f}'.format(np.linalg.norm(y-np.dot(Phi, w)) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks correct. In the video, we saw that the sum of residuals gives us the maximum likelihood estimate of the noise variance through this formula:\n",
    "$$\n",
    "\\sigma^2_{\\text{MLE}} = \\frac{\\parallel \\mathbf{y} - \\mathbf{\\Phi}\\mathbf{w}\\parallel_2^2}{N}.\n",
    "$$\n",
    "Let's compute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2_MLE = sum_res[0] / num_obs\n",
    "sigma_MLE = np.sqrt(sigma2_MLE)\n",
    "print('True sigma = {0:1.4f}'.format(sigma_true))\n",
    "print('MLE sigma = {0:1.4f}'.format(sigma_MLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize this noise.\n",
    "The prediction at each $x$ is Gaussian with mean $\\mathbf{w}^T\\boldsymbol{\\phi}(x)$ and variance $\\sigma_{\\text{MLE}}^2$.\n",
    "So, we can simply create a 95% credible interval by subtracting and adding (about) two $\\sigma_{\\text{MLE}}$ to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "# Some points on which to evaluate the regression function\n",
    "xx = np.linspace(-1, 1, 100)\n",
    "# The true connection between x and y\n",
    "yy_true = w0_true + w1_true * xx + w2_true * xx ** 2\n",
    "# The mean prediction of the model we just fitted\n",
    "Phi_xx = get_polynomial_design_matrix(xx[:, None], degree)\n",
    "yy = np.dot(Phi_xx, w)\n",
    "# Lower bound for 95% credible interval\n",
    "sigma_MLE = np.sqrt(sigma2_MLE)\n",
    "yy_l = yy - 2.0 * sigma_MLE\n",
    "# Upper bound for 95% credible interval\n",
    "yy_u = yy + 2.0 * sigma_MLE\n",
    "# plot mean prediction\n",
    "ax.plot(xx, yy, '--', label='Mean prediction')\n",
    "# plot shaded area for 95% credible interval\n",
    "ax.fill_between(xx, yy_l, yy_u, alpha=0.25, label='95% credible interval')\n",
    "# plot the data again\n",
    "ax.plot(x, y, 'kx', label='Observed data')\n",
    "# overlay the true \n",
    "ax.plot(xx, yy_true, label='True response surface')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "+ Increase the number of observations ``num_obs`` and notice that the likelihood noise converges to the true measurement noise.\n",
    "+ Change the polynomial degree to one so that you just fit a line. What does the model think about the noise now?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
