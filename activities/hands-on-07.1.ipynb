{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 7.1: Sampling Estimates of Expectations\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- To use the law of large numbers to estimate expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The law of large numbers\n",
    "\n",
    "### The strong law of large numbers\n",
    "Take an infinite series of independent random variables $X_1,X_2,\\dots$ with the same distribution, any distribution.\n",
    "Such a sequence of random variables is typically called an iid sequence for *independnet identically distributed*.\n",
    "Let $\\mu = \\mathbb{E}[X_i]$ be the common mean of these random variables.\n",
    "The *strong law of larger numbers* states the sampling average,\n",
    "$$\n",
    "\\bar{X}_N = \\frac{X_1+\\dots X_N}{N} = \\frac{1}{N}\\sum_{i=1}^NX_i,\n",
    "$$\n",
    "converges almost surely to $\\mu$ as the number of samples $N$ goes to infinity.\n",
    "Mathematically, we write:\n",
    "$$\n",
    "\\bar{X}_N=\\frac{1}{N}\\sum_{i=1}^NX_i\\rightarrow \\mu\\;\\text{a.s.}\n",
    "$$\n",
    "The a.s. (almost surely) is a technical term from measure theory which means that the probability of this convergence happening is one.\n",
    "\n",
    "### Demonstration with a synthetic example\n",
    "Let's demonstrate the law of large numbers.\n",
    "We are going to take a Beta random variable:\n",
    "$$\n",
    "X\\sim\\text{Beta}(\\alpha,\\beta),\n",
    "$$\n",
    "where $\\alpha$ and $\\beta$ is positive numbers.\n",
    "We know that the expectation of the Beta is (see [wiki](https://en.wikipedia.org/wiki/Beta_distribution)):\n",
    "$$\n",
    "\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta}.\n",
    "$$\n",
    "Let's test if the law of large numbers holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "# Create a Beta:\n",
    "alpha = 2.0\n",
    "beta = 3.0\n",
    "X = st.beta(alpha, beta)\n",
    "\n",
    "# The number of samples to take\n",
    "N = 5\n",
    "x_samples = X.rvs(N)\n",
    "\n",
    "# Find the real mean (expectation):\n",
    "mu = X.mean()\n",
    "# Find the sampling estimate of the mean:\n",
    "x_bar = x_samples.mean()\n",
    "\n",
    "# Print the results\n",
    "print('E[X] = {0:1.4f}'.format(mu))\n",
    "print('The law of large numbers with N={0:d} samples estimates it as: {1:1.4f}'.format(N, x_bar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Increase the number of samples $N$ until you get closer to the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Monte Carlo method for estimating integrals\n",
    "Now we will use the strong law of large numbers to estimate integrals.\n",
    "In particular, we will start with this integral:\n",
    "$$\n",
    "I = \\mathbb{E}[g(X)]=\\int g(x) p(x) dx,\n",
    "$$\n",
    "where $X\\sim p(x)$ and $g(x)$ is a function of $x$.\n",
    "Let $X_1,X_2,\\dots$ be independent copies of $X$.\n",
    "Then consider the random variables $Y_1 = g(X_1), Y_2 = g(X_2), \\dots$\n",
    "These random variables are also independent and identically distributed.\n",
    "So, the strong law of large number holds for them and we get that their sampling average converges to their mean:\n",
    "$$\n",
    "\\bar{I}_N=\\frac{g(X_1)+\\dots+g(X_N)}{N}=\\frac{Y_1+\\dots+Y_N}{N}\\rightarrow I,\\;\\text{a.s.}\n",
    "$$\n",
    "This is the *Monte Carlo way for estimating integrals*.\n",
    "\n",
    "### Example: 1D expectation\n",
    "Let's try it out with a test function in 1D (Example 3.4 of Robert & Casella (2004)).\n",
    "Assume that $X\\sim\\mathcal{U}([0,1])$ and pick:\n",
    "$$\n",
    "g(x) = \\left(\\cos(50x) + \\sin(20x)\\right)^2.\n",
    "$$\n",
    "The correct value for the expectation can be found analytically and it is:\n",
    "$$\n",
    "\\mathbb{E}[g(x)] = 0.965.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "g = lambda x: (np.cos(50 * x) + np.sin(20 * x)) ** 2\n",
    "\n",
    "# Let's visualize is first\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "x = np.linspace(0, 1, 300)\n",
    "ax.plot(x, g(x))\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$g(x)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples to take\n",
    "N = 100  \n",
    "# Generate samples from X\n",
    "x_samples = np.random.rand(N)\n",
    "# Get the corresponding Y's\n",
    "y_samples = g(x_samples)\n",
    "# Evaluate the sample average for all sample sizes (see https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html)\n",
    "I_running = np.cumsum(y_samples) / np.arange(1, N + 1)\n",
    "\n",
    "# Make the plot\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(np.arange(1, N+1), I_running)\n",
    "ax.plot(np.arange(1, N+1), [0.965] * N, color='r')\n",
    "ax.set_xlabel('$N$')\n",
    "ax.set_ylabel(r'$\\bar{I}_N$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Increase ``N`` until you get an answer that is close enough to the correct answer (the red line).\n",
    "+ Reduce ``N`` back to a small number, say 1,000. Run the code 2-3 times to observe that every time you get a slightly different answer..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
