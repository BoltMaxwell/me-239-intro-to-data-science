{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 13.1: Dimensionality Reduction\n",
    "\n",
    "## Objectives\n",
    "+ Understand the dimensionality reduction problem\n",
    "+ Use principal component analysis to solve the dimensionality reduction problem\n",
    "\n",
    "Through out this lecture we will be using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "The MNIST dataset consists of thousands of images of handwritten digits from $0$ to $1$.\n",
    "The dataset is a standard benchmark in machine learning.\n",
    "Here is how to get the dataset from the tensorflow library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "# Download the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comes with inputs (that are images of digits) and labels (which is the label of the digit).\n",
    "We are not going to use the labels in this lecture as we will be doing unsupervised learning.\n",
    "Let's look at the dimensions of the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is a 3D array.\n",
    "The first dimension is 60,0000. This is the number of different images that we have.\n",
    "Then each image consists of 28x28 pixels.\n",
    "Here is the first image in terms of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each number corresponds to the pixel value.\n",
    "Say, zero is a white pixel and 255 is a black pixel.\n",
    "Values between 0 and 255 correspond to some shade of gray.\n",
    "Here is how to visualize the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this handout, I want to work with just images of threes.\n",
    "So, let me just keep all the threes and throw away all other data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = x_train[y_train == 3]\n",
    "threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 6,131 threes. That's enough.\n",
    "Now, each image is a 28x28 matrix.\n",
    "We do not like that.\n",
    "We would like to have vectors instead of matrices.\n",
    "So, we need to *vectorize* the matrices.\n",
    "That's easy to do. We just have to reshape them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_threes = threes.reshape((threes.shape[0], threes.shape[1] * threes.shape[2]))\n",
    "vectorized_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. You see that we now have 6,131 vectors each with 784 dimensions.\n",
    "That is our dataset.\n",
    "Let's apply PCA to it to reduce its dimensionality.\n",
    "We are going to use the [PCA class of scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "Here is how to import the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is how to initialize the model and fit it to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.98, whiten=True).fit(vectorized_threes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the complete definition of the inputs to the ``PCA`` class, see its documentation.\n",
    "The particular parameters that I define above have the following effect:\n",
    "- ``n_components``: If you set this to an integer, the PCA will have this many components. If you set it to a number between $0$ and $1$, say 0.98, then PCA will keep as many components as it needs in order to capture 98% of the variance of the data. I use the second type of input.\n",
    "- ``whiten``: This ensures that the projections have unit variance. If you don't specify this then their variance will be the corresponding eigenvalue. Setting ``whiten=True`` is consistent with the theory developed in the video.\n",
    "\n",
    "Okay, so now that the model is trained let's investigate it.\n",
    "First, we asked PCA to keep enough components so that it can describe 98% of the variance.\n",
    "How many did it actually keep?\n",
    "Here is how to check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It kept 227 compents. This doesn't look very impressive but we will take it for now.\n",
    "\n",
    "Now, let's focus on the eigenvalues of the covariance matrix.\n",
    "Here is how to get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(pca.explained_variance_)\n",
    "ax.set_xlabel('$i$')\n",
    "ax.set_ylabel(r'$\\lambda_i$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the sum of first $k$ eigenvalues, $\\sum_{i=1}^k\\lambda_i$ tells you how much variance is explained with a model that keeps the first $k$ PCA components.\n",
    "\n",
    "Okay.\n",
    "As we discussed in the lecture videos, each of the observations expanded as follows:\n",
    "$$\n",
    "\\mathbf{x}_j = \\mathbf{m} + \\sum_{i=1}^kz_{ji}\\sqrt{\\lambda}_i\\mathbf{v}_i.\n",
    "$$\n",
    "Let's visualize first the mean $\\mathbf{m}$.\n",
    "It is this vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.mean_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so let's reshape it and plot it as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=64)\n",
    "ax.imshow(pca.mean_.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go for the eigenvectors $\\mathbf{v}_i$.\n",
    "Here is where the are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here is how to visualize them as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    fig, ax = plt.subplots(dpi=64)\n",
    "    ax.imshow(pca.components_[i, :].reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visulize the first two principal components $\\mathbf{z}_j$ of each observation $\\mathbf{x}_j$.\n",
    "This will essentially project the dataset from 784 dimensions to two dimensions.\n",
    "Here is how to find the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pca.transform(vectorized_threes)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.scatter(Z[:, 0], Z[:, 1])\n",
    "ax.set_xlabel('$z_1$')\n",
    "ax.set_ylabel('$z_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Each dot in this plot corresponds to an image of a 3.\n",
    "This is nice, but not the best thing we can do in terms of visualization.\n",
    "It would be nice if we could plot the actual image instead of a dot.\n",
    "Here is how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is a modification of the code found here:\n",
    "# https://stackoverflow.com/questions/35651932/plotting-img-with-matplotlib\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "def imscatter(x, y, images, cmap=plt.cm.gray_r, ax=None, zoom=1):\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    for x0, y0, image in zip(x, y, images):\n",
    "        im = OffsetImage(image, zoom=zoom, cmap=cmap, interpolation='nearest')\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "imscatter(Z[:, 0], Z[:, 1], threes, ax=ax, zoom=0.2)\n",
    "ax.set_xlabel('$z_1$')\n",
    "ax.set_ylabel('$z_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot you can clearly see the interpretation of the principal components.\n",
    "The first principal component seems to rotate the three about an axis coming out of the screen.\n",
    "The second principal component seems to change the thickness of the bottom of the three.\n",
    "We can study these effects in more detail using an interactive plot.\n",
    "Here you go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "def visualize_pca_component(i=0, z=0.0):\n",
    "    fig, ax = plt.subplots(dpi=64)\n",
    "    x = pca.mean_ + z * np.sqrt(pca.explained_variance_[i]) * pca.components_[i]\n",
    "    ax.imshow(x.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "interactive(visualize_pca_component, i=[0, 1, 2, 3], z=np.linspace(-2.0, 2.0, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Keeping the index $i=0$ fixed, play with the corresponding $z$ and observe that it rotates the three.\n",
    "+ Change $i$ to $1,2$ and $3$ and study the effect of the corresponding principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to study the reconstruction error for the validation dataset.\n",
    "First, throw everything that is not a three:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_threes = x_test[y_test==3]\n",
    "valid_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1,010 images for validation.\n",
    "We still need to vectorize.\n",
    "Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_valid_threes = valid_threes.reshape(valid_threes.shape[0], valid_threes.shape[1] * valid_threes.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what I am going to do is project all the validation points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_valid = pca.transform(vectorized_valid_threes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then reconstruct them and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which validation example would you like to look at:\n",
    "idx = 1\n",
    "# How many componentd would you like to use for the reconstruction\n",
    "n_components = 1\n",
    "# Here is how to reconstruct:\n",
    "x = pca.inverse_transform(\n",
    "    np.hstack([Z_valid[idx][:n_components], \n",
    "               np.zeros((Z_valid.shape[1] - n_components,))]))\n",
    "\n",
    "# Visualize the original image\n",
    "fig, ax = plt.subplots(dpi=64)\n",
    "ax.imshow(valid_threes[idx], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "# Visualize the reconstructed image\n",
    "fig, ax = plt.subplots(dpi=64)\n",
    "ax.imshow(x.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "+ Play with the code block above increasing ``n_components`` to 2, 4, 8, and so on up to 227. Observe how the reconstruction becomes better (but not perfect).\n",
    "+ Repeat the above question, but change also the ``idx`` variable so that you see some more examples of three.\n",
    "+ Go back a few code blocks, and change your validation set to include only fives.\n",
    "You must change this:\n",
    "```\n",
    "valid_threes = x_test[y_test==3]\n",
    "valid_threes.shape\n",
    "```\n",
    "to this:\n",
    "```\n",
    "valid_threes = x_test[y_test==5]\n",
    "valid_threes.shape\n",
    "```\n",
    "Don't bother renaming ``valid_threes``.\n",
    "Can the PCA model constructed with threes describe 5s? Why yes or why not?\n",
    "+ Repeat the previous question with a couple of other digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
