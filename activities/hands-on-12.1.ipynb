{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 12.1: Clustering using k-means\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ To demonstrate clustering using k-means\n",
    "\n",
    "Let's start by generating a synthetic dataset using with three clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the random seed so that we all get the same data\n",
    "np.random.seed(123456)\n",
    "# Make synthetic dataset for clustering\n",
    "num_clusters_true = 3\n",
    "# The means of each cluster\n",
    "mu_true = 3.0 * np.random.randn(num_clusters_true, 2)\n",
    "# The variance of the observations around the cluster\n",
    "sigma_true = 0.5\n",
    "# How many observations to generate per cluster\n",
    "num_obs_cluster = [50, 50, 50]\n",
    "# Generate the data\n",
    "data = []\n",
    "for i in range(num_clusters_true):\n",
    "    x_i = mu_true[i] + sigma_true * np.random.randn(num_obs_cluster[i], 2)\n",
    "    data.append(x_i)\n",
    "data = np.vstack(data)\n",
    "# Permute the data so that order info is lost\n",
    "data = np.random.permutation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the data forgetting about the underlying clusers that gave rise to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(data[:, 0], data[:, 1], '.')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to implement the K-means algorithm from scratch.\n",
    "Instead, we are going to use the implementation that can be found in [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "Here is how easy it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the KMeans class:\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit the model using the data:\n",
    "model = KMeans(n_clusters=3).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you can access the cluster centers (the $\\mu_k$'s) from the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the identified cluster centers to the actual cluster centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very close to the true ones\n",
    "mu_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means has also labeled each observation point with its cluster id.\n",
    "Here is how to get this info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The clsuter of each point\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 2D observations, we can actually visualize the clusters.\n",
    "Here is a nice way to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(data)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this seems to work perfectly.\n",
    "However, notice that we asked K-means to find three clusters which happens to be the true number of clusters in our dataset.\n",
    "What would happen if we had asked K-means to find a larger number of clusters, say 5?\n",
    "Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = KMeans(n_clusters=5).fit(data)\n",
    "labels = model5.predict(data)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "+ We saw what happens when you ask K-means to find more clusters than there actually exist. What would happen, if you asked it to find a smaller number of clusters? Try $K=1$ and $K=2$ in the code block immediatly above. What do you observe? Can choose between $K=1, 2,$ or $3$?\n",
    "+ Rerun the entire example from the very first code block but this time set the number of true clusters to 6. Investigate what happens when you try to fit K-means with a very small number of clusters, what happens when you pick $K$ to be around 6, and what happens when you pick a very big $K$, say 10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
