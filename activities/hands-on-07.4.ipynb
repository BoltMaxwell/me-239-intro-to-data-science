{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 7.4: Sampling Estimates of the Probability Density via Histograms\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- To estimate probability density via histrograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the probability density function via histograms\n",
    "\n",
    "As before take $X$ to be a random variable and $Y=g(X)$ a function of $X$.\n",
    "We wish to approximate from samples the probability density $p(y)$ of $Y=g(X)$.\n",
    "We start by spliting the domain of $y$ into $M$ small bins.\n",
    "Assume that these bins have bounds $b_0, b_1, \\dots, b_M$.\n",
    "That is, the first bin is $[b_0,b_1]$, the second one is $[b_1,b_2]$, etc.\n",
    "We will approximate $p(y)$ with a constant inside its bin.\n",
    "That is, the approximation is:\n",
    "$$\n",
    "\\hat{p}_M(y) = \\sum_{j=1}^Mc_j 1_{[b_{j-1}, b_j]}(y),\n",
    "$$\n",
    "where the $c_j$'s are constants to be determined.\n",
    "Each one of these constants is the probability that a sample of $Y$ falls inside the bin, i.e.,\n",
    "$$\n",
    "c_j = p(b_{j-1}\\le Y \\le b_j).\n",
    "$$\n",
    "Of course, this probability can be written as \n",
    "$$\n",
    "c_j = F(b_j) - F(b_{j-1}),\n",
    "$$\n",
    "where $F(y)$ is the CDF of $Y$.\n",
    "Therefore, we can approximate the constants using our estimate of the CDF.\n",
    "In the notation of the previous section, we have that:\n",
    "$$\n",
    "\\bar{c}_{j,N} := \\bar{F}_N(b_j) - \\bar{F}_N(b_{j-1}) \\rightarrow c_j\\;\\text{a.s.}\n",
    "$$\n",
    "Of course, this is nothing more but:\n",
    "$$\n",
    "\\bar{c}_{j,N} = \\frac{\\text{number of samples that fall in bin }[b_{j-1},b_j]}{N}\n",
    "$$\n",
    "Putting everything together, our estimate for the PDF $p(y)$ is:\n",
    "$$\n",
    "\\hat{p}_{M,N}(y) = \\sum_{j=1}^M\\bar{c}_{j,N} 1_{[b_{j-1}, b_j]}(y),\n",
    "$$\n",
    "which does converge to $p(y)$ (in some sense) as both $N$ and $M$ go to infinity.\n",
    "\n",
    "### Example: 1D CDF\n",
    "We will continue using the 1D test function of Example 3.4 of Robert & Casella (2004).\n",
    "Assume that $X\\sim\\mathcal{U}([0,1])$ and pick:\n",
    "$$\n",
    "g(x) = \\left(\\cos(50x) + \\sin(20x)\\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function here:\n",
    "g = lambda x: (np.cos(50 * x) + np.sin(20 * x)) ** 2\n",
    "\n",
    "# Again, we do not need to write any code for the histogram\n",
    "# It's already implemented in several packages.\n",
    "# We will use the matplotlib implementation\n",
    "\n",
    "# Maximum number of samples to take\n",
    "max_n = 10000 \n",
    "# The number of bins\n",
    "num_bins = 100\n",
    "# Generate samples from X\n",
    "x_samples = np.random.rand(max_n)\n",
    "# Get the corresponding Y's\n",
    "y_samples = g(x_samples)\n",
    "\n",
    "# Make the plot\n",
    "for N in [100, 1000, max_n]:\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    ax.hist(y_samples[:N], label='$N={0:d}$'.format(N), bins=num_bins,\n",
    "        density=True, # This is required to divide by N\n",
    "        alpha=0.25)\n",
    "    ax.set_xlabel('$y$')\n",
    "    ax.set_ylabel(r'$\\hat{{p}}_{{M={0:d},N}}(y)$'.format(num_bins))\n",
    "    plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "+ Experiment with the number of bins $M$. Repeat the code above with $M=5, 10$ and $1000$. What do you observe? What happens when you have to few bins? What happens when you have to many bins? You should pick the number of bins and $N$ together. As a rule of thumb $N$ should be about ten times $M$. For a given choice of $M$, it is possible to pick how many $N$'s you need using what we will learn in lecture 10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
