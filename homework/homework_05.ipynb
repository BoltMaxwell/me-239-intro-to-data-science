{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "**Due 10/18/2020 on gradescope.**\n",
    "\n",
    "## References\n",
    "\n",
    "+ Lecture 8.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "+ Type your name and email in the \"Student details\" section below.\n",
    "+ Develop the code and generate the figures you need to solve the problems using this notebook.\n",
    "+ For the answers that require a mathematical proof or derivation you can either:\n",
    "    \n",
    "    - Type the answer using the built-in latex capabilities. In this case, simply export the notebook as a pdf and upload it on gradescope; or\n",
    "    - You can print the notebook (after you are done with all the code), write your answers by hand, scan, turn your response to a single pdf, and upload on gradescope.\n",
    "\n",
    "+ The total homework points are 100. Please note that the problems are not weighed equally.\n",
    "\n",
    "**Note**: Please match all the pages corresponding to each of the questions when you submit on gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student details\n",
    "\n",
    "+ **First Name:**\n",
    "+ **Last Name:**\n",
    "+ **Email:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "The [San Andreas fault](https://en.wikipedia.org/wiki/San_Andreas_Fault) extends through California forming the boundary between the Pacific and the North American tectonic plates.\n",
    "It has caused some of the major earthquakes on Earth.\n",
    "We are going to focus on Southern California and we would like to assess the probability of a major earthquake, defined as an earthquake of magnitude 6.5 or greater, during the next ten years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. The first thing we are going to do is go over a [database of past earthquakes](https://scedc.caltech.edu/significant/chron-index.html) that have occured in Southern California and collect the relevant data. We are going to start at 1900 because data before that time may are unreliable.\n",
    "Go over each decade and count the occurence of a major earthquake (i.e., count the number of organge and red colors in each decade). We have done this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_data = np.array([\n",
    "    0, # 1900-1909\n",
    "    1, # 1910-1919\n",
    "    2, # 1920-1929\n",
    "    0, # 1930-1939\n",
    "    3, # 1940-1949\n",
    "    2, # 1950-1959\n",
    "    1, # 1960-1969\n",
    "    2, # 1970-1979\n",
    "    1, # 1980-1989\n",
    "    4, # 1990-1999\n",
    "    0, # 2000-2009\n",
    "    2 # 2010-2019 \n",
    "])\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.bar(np.linspace(1900, 2019, eq_data.shape[0]), eq_data, width=10)\n",
    "ax.set_xlabel('Decade')\n",
    "ax.set_ylabel('# of major earthquakes in Southern CA');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. The right way to model the number of earthquakes $X_n$ in a decade $n$ is using a Poisson distribution with unknown rate parameter $\\lambda$, i.e.,\n",
    "$$\n",
    "X_n | \\lambda \\sim \\operatorname{Poisson}(\\lambda).\n",
    "$$\n",
    "Here we have $N = 12$ observations, say $x_{1:N} = (x_1,\\dots,x_N)$ (stored in ``eq_data`` above).\n",
    "Find the *joint probability* (otherwise known as the likelihood) $p(x_{1:N}|\\lambda)$ of these random variables.<br>\n",
    "**Answer:**\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. The rate parameter $\\lambda$ (number of major earthquakes per ten years) is positive. What prior distribution should we assign to it if we expect it to be around 2?\n",
    "A convenient choice here is to pick a [Gamma](https://en.wikipedia.org/wiki/Gamma_distribution), see also [the scipy.stats page for the Gamma](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html) because it results in an analytical posterior.\n",
    "We write:\n",
    "$$\n",
    "\\lambda \\sim \\operatorname{Gamma}(\\alpha, \\beta),\n",
    "$$\n",
    "where $\\alpha$ and $\\beta$ are positive *hyper-parameters* that we have to set to represent our prior state of knowledge.\n",
    "The PDF is:\n",
    "$$\n",
    "p(\\lambda) = \\frac{\\beta^\\alpha \\lambda^{\\alpha-1}e^{-\\beta \\lambda}}{\\Gamma(\\alpha)},\n",
    "$$\n",
    "where we are not conditioning on $\\alpha$ and $\\beta$ because they should be fixed numbers.\n",
    "Use the code below to pick some some reasonable values for $\\alpha$ and $\\beta$.\n",
    "Hint: Notice that the maximum entropy distribution for a positive parameter with known expectation is the [Exponential](https://en.wikipedia.org/wiki/Exponential_distribution), e.g., see the Table in [this wiki page](https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution). Then notice that the Exponential is a special case of the Gamma (set $\\alpha=1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "alpha = 1.0  # Pick them here\n",
    "beta = 1.0   # Pick them here\n",
    "lambda_prior = st.gamma(alpha, scale=1.0 / beta) # Make sure you understand why scale = 1 / beta\n",
    "lambdas = np.linspace(0, lambda_prior.ppf(0.99), 100)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(lambdas, lambda_prior.pdf(lambdas))\n",
    "ax.set_xlabel('$\\lambda$ (# or major earthquakes per decade)')\n",
    "ax.set_ylabel('$p(\\lambda)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Show that the posterior of $\\lambda$ conditioned on $x_{1:N}$ is also a Gamma, but with updated hyperparameters.\n",
    "Hint: When you write down the posterior of $\\lambda$ you can drop any multiplicative term that does not depend on it as it will be absorbed in the normalization constnat. This will simplify the notation a little bit.\n",
    "<br>\n",
    "**Answer:**\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Prior-likelihood pairs that result in a posterior with the same form as the prior as known as conjugate distributions. Conjugate distributions are your only hope for analytical Bayesian inference.\n",
    "As a sanity check, look at the wikipedia page for [conjugate priors](https://en.wikipedia.org/wiki/Conjugate_prior), locate the Poisson-Gamma pair and verify your answer above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Plot the prior and the posterior of $\\lambda$ on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_post = 1.0 # Your expression for alpha posterior here\n",
    "beta_post = 1.0 # Your expression for beta posterior here\n",
    "lambda_post = st.gamma(alpha_post, scale=1.0 / beta_post)\n",
    "lambdas = np.linspace(0, lambda_post.ppf(0.99), 100)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(lambdas, lambda_post.pdf(lambdas))\n",
    "ax.set_xlabel('$\\lambda$ (# or major earthquakes per decade)')\n",
    "ax.set_ylabel('$p(\\lambda|x_{1:N})$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F. Let's work out the predictive distribution for the number of major earthquakes during the next decade.\n",
    "This is something that we did not do in class, but it will appear again and again in future lectures.\n",
    "Let $X$ be the random variable corresponding to the number of major eathquakes during the next decade.\n",
    "We need to calculate:\n",
    "$$\n",
    "p(x|x_{1:N}) = \\text{our state of knowledge about $X$ after seeing the data}.\n",
    "$$\n",
    "How do we do this?\n",
    "We just use the sum rule:\n",
    "$$\n",
    "p(x|x_{1:N}) = \\int_{0}^\\infty p(x|\\lambda, x_{1:N}) p(\\lambda|x_{1:N})d\\lambda = \\int_{0}^\\infty p(x|\\lambda) p(\\lambda|x_{1:N})d\\lambda,\n",
    "$$\n",
    "where going from the middle step to the rightmost one we used the assumption that the number of earthquakes occuring in each decade is independent.\n",
    "Carry out this integral and show that it will give you the [negative Binomial](https://en.wikipedia.org/wiki/Negative_binomial_distribution) distribution $\\operatorname{NB}(r,p)$, see also its [scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.nbinom.html), page with parameters\n",
    "$$\n",
    "r = \\alpha + \\sum_{n=1}^N x_n,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "p = \\frac{1}{\\beta + N + 1}.\n",
    "$$\n",
    "The probability density of the negative Binomial is (using the notation of wikipedia):\n",
    "$$\n",
    "\\operatorname{NB}(k|r,p) = {k + r - 1\\choose k}(1-p)^rp^k.\n",
    "$$\n",
    "You may also use the fact that:\n",
    "$$\n",
    "\\begin{split}\n",
    "\\int_0^\\infty y^{\\alpha-1}e^{-\\beta y}dy &=\n",
    "\\text{inverse normalization constant of }\\operatorname{Gamma}(\\alpha,\\beta)\\\\\n",
    "&= \\frac{\\Gamma(\\alpha)}{\\beta^\\alpha},\n",
    "\\end{split}\n",
    "$$\n",
    "and that $\\Gamma(n+1) = n!$.\n",
    "\n",
    "**Answer:**\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G. Plot the predictive distribution $p(x|x_{1:N})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1.0 # Your expression for r here\n",
    "p = 0.2 # Your expression for theta here\n",
    "X = st.nbinom(r, 1.0 - p) # Please pay attention to the fact that the wiki and scipy.stats\n",
    "                          # use slightly different definitions\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H. What is the probability that at least one major earthquake will occur during the next decade?<br>\n",
    "**Answer:**\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. What is the probability that at least one major earthquake will occur during the next two decades?<br>\n",
    "**Answer:**\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J. Find a 95\\% credible interval for $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here and print() your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K. Find the $\\lambda$ that minimizes the absolute loss (see lecture), call it $\\lambda^*_N$.\n",
    "Then, plot the fully Bayesian predictive $p(x|x_{1:N})$ in the same figure as $p(x|\\lambda^*_N)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here and print() your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L. Draw replicated data from the model and compare them to the observed data. Hint: Complete the missing code at the places indicated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of replicated datasets\n",
    "n_rep = 9\n",
    "# A variable to store the replicated data:\n",
    "x_rep = np.ndarray((n_rep, eq_data.shape[0]))\n",
    "for i in range(n_rep):\n",
    "    # Student code 1: Take a sample of lambda from its posterior:\n",
    "    lambda_post_sample = # YOUR CODE HERE\n",
    "    # Student code 2: Take a sample of size eq_data.shape[0] from the Poisson with parameter\n",
    "    # lambda_post_sample (You can use st.poisson)\n",
    "    x_rep[i, :] = # YOUR CODE HERE\n",
    "fig, ax = plt.subplots(5, 2, sharex='all', sharey='all', figsize=(20, 20))\n",
    "ax[0, 0].bar(np.linspace(1900, 2019, eq_data.shape[0]), eq_data, width=10, color='red')\n",
    "for i in range(1, n_rep + 1):\n",
    "    ax[int(i / 2), i % 2].bar(np.linspace(1900, 2019, eq_data.shape[0]), x_rep[i-1], width=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M. Plot the histograms and calculate the Bayesian p-values of the following test-quantities:\n",
    "\n",
    "+ Maximum number of consecutive decades with no earthquakes.\n",
    "+ Maximum number of consecutive decades with earthquakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test quantity as a function of the data:\n",
    "def T_eq_max_neq(x):\n",
    "    \"\"\"\n",
    "    Return the maximum number of consecutive decades with no earthquakes.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    result = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i] != 0:\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            result = max(result, count)\n",
    "    return result\n",
    "    \n",
    "# The observed test quantity\n",
    "T_eq_max_neq_obs = T_eq_max_neq(eq_data)\n",
    "print('The observed test quantity is {0:d}'.format(T_eq_max_neq_obs))\n",
    "# Draw replicated data\n",
    "n_rep = 5000\n",
    "x_rep = np.ndarray((n_rep, eq_data.shape[0]))\n",
    "for i in range(n_rep):\n",
    "    # The code below is the same as in P1.L\n",
    "    # Student code 1: Take a sample of lambda from its posterior:\n",
    "    lambda_post_sample = # YOUR CODE HERE\n",
    "    # Student code 2: Take a sample of size eq_data.shape[0] from the Poisson with parameter\n",
    "    # lambda_post_sample (You can use st.poisson)\n",
    "    x_rep[i, :] = # YOUR CODE HERE\n",
    "# Evaluate the test quantity\n",
    "T_eq_max_neq_rep = np.ndarray(x_rep.shape[0])\n",
    "for i in range(x_rep.shape[0]):\n",
    "    T_eq_max_neq_rep[i] = T_eq_max_neq(x_rep[i, :])\n",
    "# Estimate the Bayesian p-value\n",
    "p_val = np.sum(np.ones((n_rep,))[T_eq_max_neq_rep > T_eq_max_neq_obs]) / n_rep\n",
    "print('The Bayesian p_value is {0:1.4f}'.format(p_val))\n",
    "# Do the plot\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "tmp = ax.hist(T_eq_max_neq_rep, density=True, alpha=0.25, label='Replicated test quantity')[0]\n",
    "ax.plot(T_eq_max_neq_obs * np.ones((50,)), np.linspace(0, tmp.max(), 50), 'k', label='Observed test quantity')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here for the second test quantity (maximum number of consecutive decades with earthquakes)\n",
    "# Hint: copy paste your code from the previous cell and make the necessary modifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
